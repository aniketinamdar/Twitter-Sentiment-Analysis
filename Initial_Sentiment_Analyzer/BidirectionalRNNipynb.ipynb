{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aniketinamdar/Twitter-Sentiment-Analysis-using-Support-Vector-Machine-/blob/main/BidirectionalRNNipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing necessary libraries"
      ],
      "metadata": {
        "id": "K8GLRGEK1ILL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Atn04bbCWLes",
        "outputId": "822df205-d3be-4a04-a736-7d3a8da35af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import regularizers\n",
        "from keras.layers import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "ZK4bBfR-n42t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reading the csv file"
      ],
      "metadata": {
        "id": "aYSPfyag1PAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Dataset/Twitter_Data.csv',nrows=10000)"
      ],
      "metadata": {
        "id": "d9om0GeiihX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9KLUO6Hi0Lp",
        "outputId": "bdb5aeef-2371-4519-a7e3-753efceb17aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                              clean_text  category\n",
              "0     when modi promised “minimum government maximum...        -1\n",
              "1     talk all the nonsense and continue all the dra...         0\n",
              "2     what did just say vote for modi  welcome bjp t...         1\n",
              "3     asking his supporters prefix chowkidar their n...         1\n",
              "4     answer who among these the most powerful world...         1\n",
              "...                                                 ...       ...\n",
              "9995  modi made 1000 promises manifesto after electi...         0\n",
              "9996                  jds leaders also saying modi modi         0\n",
              "9997  woh sirf modi gaali raha tha and changed his m...         1\n",
              "9998  you must say what you witnessed since 2014 you...         1\n",
              "9999  knows once modi comes again his entire family ...        -1\n",
              "\n",
              "[10000 rows x 2 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBNKv04MBq-f",
        "outputId": "fa63b12f-9cf0-4690-e972-dafac86b12e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   clean_text  9999 non-null   object\n",
            " 1   category    10000 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 156.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.clean_text = df.clean_text.fillna('')"
      ],
      "metadata": {
        "id": "_D4zd5CfBtP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1dy7U11BsYg",
        "outputId": "a3698df9-8e88-4943-e95c-fd4e40c0f199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   clean_text  10000 non-null  object\n",
            " 1   category    10000 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 156.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEze6l1E0CGC",
        "outputId": "c30408f1-904b-4aed-e5e0-c0b64cc22f97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9zyG2Gu0TBU",
        "outputId": "13f71532-e2a3-4e29-e53c-ab030998ae81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Preprocessing"
      ],
      "metadata": {
        "id": "zgCld_ec1FqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df['clean_text'] = df['clean_text'].str.replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','')\n",
        "df['clean_text'] = df['clean_text'].astype(str).replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','')"
      ],
      "metadata": {
        "id": "kWgPMLlg0cJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_text'] = df['clean_text'].astype(str).replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','')"
      ],
      "metadata": {
        "id": "nEk39oXe0idz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_text'] = df['clean_text'].astype(str).replace(r\"[\\\"\\'\\|\\?\\=\\.\\@\\#\\*\\,]\", '')"
      ],
      "metadata": {
        "id": "jdPZNKAk0iWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_text'] = df['clean_text'].astype(str).replace(\"\\'\", '')"
      ],
      "metadata": {
        "id": "-58iqWua0iNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oc3X5qVK1-6z",
        "outputId": "74afd950-2c60-46ac-dc7a-fbec7cb36e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                              clean_text  category\n",
              "0     when modi promised “minimum government maximum...        -1\n",
              "1     talk all the nonsense and continue all the dra...         0\n",
              "2     what did just say vote for modi  welcome bjp t...         1\n",
              "3     asking his supporters prefix chowkidar their n...         1\n",
              "4     answer who among these the most powerful world...         1\n",
              "...                                                 ...       ...\n",
              "9995  modi made 1000 promises manifesto after electi...         0\n",
              "9996                  jds leaders also saying modi modi         0\n",
              "9997  woh sirf modi gaali raha tha and changed his m...         1\n",
              "9998  you must say what you witnessed since 2014 you...         1\n",
              "9999  knows once modi comes again his entire family ...        -1\n",
              "\n",
              "[10000 rows x 2 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "lBwC08viX88C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_str = df['clean_text']\n",
        "new_str = re.sub('\"', '', example_str)"
      ],
      "metadata": {
        "id": "zCDPEM7ybqS4",
        "outputId": "5c83a8d6-acaf-422e-841a-d2f5e294a953",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-896237c907c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'example_str' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXuvRnpdYvnA",
        "outputId": "2048542c-823b-444d-df27-4e0e0905def4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       when modi promised “minimum government maximum...\n",
              "1       talk all the nonsense and continue all the dra...\n",
              "2       what did just say vote for modi  welcome bjp t...\n",
              "3       asking his supporters prefix chowkidar their n...\n",
              "4       answer who among these the most powerful world...\n",
              "                              ...                        \n",
              "9995    modi made 1000 promises manifesto after electi...\n",
              "9996                    jds leaders also saying modi modi\n",
              "9997    woh sirf modi gaali raha tha and changed his m...\n",
              "9998    you must say what you witnessed since 2014 you...\n",
              "9999    knows once modi comes again his entire family ...\n",
              "Name: clean_text, Length: 10000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSdDTE7MHSYS",
        "outputId": "2d43e2eb-fec2-47e2-e796-357144a33a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   clean_text  10000 non-null  object\n",
            " 1   category    10000 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 156.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence),deacc=True))"
      ],
      "metadata": {
        "id": "nZgLmt-dmirw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detokenize(text):\n",
        "    return TreebankWordDetokenizer().detokenize(text)"
      ],
      "metadata": {
        "id": "IZ9CU-DlmsIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_to_words(df['clean_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEfwxBLH201y",
        "outputId": "5795125e-b72b-44aa-91d7-24ff9d400bde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object sent_to_words at 0x7f3aff0fb430>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_text']=detokenize(df['clean_text'])"
      ],
      "metadata": {
        "id": "glvjUdDb3GgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnCOraa_Hbys",
        "outputId": "310410b5-f6f1-4a50-bd0c-b8a0592a9cc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   clean_text  10000 non-null  object\n",
            " 1   category    10000 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 156.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test Train split"
      ],
      "metadata": {
        "id": "hAFMRDfB0jMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = train_test_split(df['clean_text'], test_size=0.2, random_state=42, shuffle=True)"
      ],
      "metadata": {
        "id": "0vLY8rGQpkCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train, Y_test = train_test_split(df['category'], test_size=0.2, random_state=42, shuffle=True)"
      ],
      "metadata": {
        "id": "Ql-d7c9j1rxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Converting sentences to word embeddings"
      ],
      "metadata": {
        "id": "GCEwZJc_5R0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 5000\n",
        "max_len = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(df['clean_text'])\n",
        "sequences = tokenizer.texts_to_sequences(df['clean_text'])\n",
        "tweets = pad_sequences(sequences, maxlen=max_len)\n",
        "print(tweets)"
      ],
      "metadata": {
        "id": "txipEoXenS91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "414eeb11-06c3-4d41-a4ac-7c21be742fb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-1e05d81aa7b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/preprocessing/text.py\u001b[0m in \u001b[0;36mfit_on_texts\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                     seq = text_to_word_sequence(\n\u001b[0m\u001b[1;32m    294\u001b[0m                         \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                         \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/preprocessing/text.py\u001b[0m in \u001b[0;36mtext_to_word_sequence\u001b[0;34m(input_text, filters, lower, split)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mtranslate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mtranslate_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaketrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslate_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Embedding Layer"
      ],
      "metadata": {
        "id": "ISruTm3A8CTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = Embedding(1000, 64)"
      ],
      "metadata": {
        "id": "WQDUhgwc4G3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bidirectional Recurrent Neural Network"
      ],
      "metadata": {
        "id": "THtZjpSy73VJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "Q0SauymP6bgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(layers.Embedding(max_words, 40, input_length=max_len))"
      ],
      "metadata": {
        "id": "o2XHEAMB61WK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))"
      ],
      "metadata": {
        "id": "lF7s1IFa7bdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(layers.Dense(3,activation='softmax'))"
      ],
      "metadata": {
        "id": "ei6S0SKV7bYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "DI62OoaI7pET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(\"best_model2.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RGBrhTO7sbM",
        "outputId": "1977e751-cfd3-4434-9503-f53ad937799f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70h_Qqfh-rBf",
        "outputId": "ffc44706-8d44-4419-aeaa-7ab5d0d0a9dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800,)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFE9HIZ5-3IW",
        "outputId": "d4575b16-5548-4cbf-ab30-342fd54ed20b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200,)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi3uqz-A-6B9",
        "outputId": "f7957fbf-0767-4819-ab9a-c97ed1aff752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800,)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHxmDlxL-7u-",
        "outputId": "775fd739-3c35-4eb2-98cd-7ce8f089a2c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200,)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, Y_train, epochs=100,validation_data=(X_test, Y_test),callbacks=[checkpoint])"
      ],
      "metadata": {
        "id": "5OWgHm8lCxzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_GPjH3WG7vJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Checking the results of the model"
      ],
      "metadata": {
        "id": "fYbbvRwE9Jbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment = ['Neutral','Negative','Positive']\n",
        "sequence = tokenizer.texts_to_sequences(['this data science article is the best ever'])\n",
        "test = pad_sequences(sequence, maxlen=max_len)\n",
        "sentiment[np.around(model.predict(test), decimals=0).argmax(axis=1)[0]]"
      ],
      "metadata": {
        "id": "2sjVr-ay9HMI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}